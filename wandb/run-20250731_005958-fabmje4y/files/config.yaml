_wandb:
    value:
        cli_version: 0.21.0
        e:
            ipnzefqshz4n1r0zhh35hvb9sp9m9nrp:
                codePath: 2.1_LSTM_Wandb.ipynb
                codePathLocal: 2.1_LSTM_Wandb.ipynb
                cpu_count: 6
                cpu_count_logical: 12
                cudaVersion: "12.9"
                disk:
                    /:
                        total: "804232626176"
                        used: "354179203072"
                email: melihak635442@gmail.com
                executable: /home/melih/Documents/Bites_CPU_Analizi/bites_cpu_venv/bin/python
                git:
                    commit: ebea5488bf0aeb4d8d97a4896ffd27621333b6f9
                    remote: git@github.com:m24ih/Bites_CPU_Analizi.git
                gpu: NVIDIA GeForce RTX 4060 Laptop GPU
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 3072
                      memoryTotal: "8585740288"
                      name: NVIDIA GeForce RTX 4060 Laptop GPU
                      uuid: GPU-1fcb879c-ca2f-354a-24bb-c9dd6765cc0b
                host: CachyOS
                memory:
                    total: "41390157824"
                os: Linux-6.15.7-3-cachyos-x86_64-with-glibc2.41
                program: /home/melih/Documents/Bites_CPU_Analizi/2.1_LSTM_Wandb.ipynb
                python: CPython 3.13.5
                root: /home/melih/Documents/Bites_CPU_Analizi
                startedAt: "2025-07-30T21:59:58.859470Z"
                writerId: ipnzefqshz4n1r0zhh35hvb9sp9m9nrp
        m: []
        python_version: 3.13.5
        t:
            "1":
                - 1
                - 5
                - 53
                - 105
            "2":
                - 1
                - 5
                - 53
                - 105
            "3":
                - 1
                - 2
                - 3
                - 13
                - 16
            "4": 3.13.5
            "5": 0.21.0
            "8":
                - 1
            "10":
                - 20
            "12": 0.21.0
            "13": linux-x86_64
batch_size:
    value: 64
dropout:
    value: 0.3
epochs:
    value: 20
hidden_dim:
    value: 128
lr:
    value: 0.0001
num_layers:
    value: 3
